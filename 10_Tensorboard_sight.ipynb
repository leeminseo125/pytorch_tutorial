{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TENSORBOARD로 모델, 데이터, 학습 시각화하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "# transforms\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))])\n",
    "\n",
    "# datasets\n",
    "trainset = torchvision.datasets.FashionMNIST('./data',\n",
    "    download=True,\n",
    "    train=True,\n",
    "    transform=transform)\n",
    "testset = torchvision.datasets.FashionMNIST('./data',\n",
    "    download=True,\n",
    "    train=False,\n",
    "    transform=transform)\n",
    "\n",
    "# dataloaders\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4,\n",
    "                                        shuffle=True, num_workers=2)\n",
    "\n",
    "\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=4,\n",
    "                                        shuffle=False, num_workers=2)\n",
    "\n",
    "# 분류 결과를 위한 상수\n",
    "classes = ('T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
    "        'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle Boot')\n",
    "\n",
    "# 이미지를 보여주기 위한 헬퍼(helper) 함수\n",
    "# (아래 `plot_classes_preds` 함수에서 사용)\n",
    "def matplotlib_imshow(img, one_channel=False):\n",
    "    if one_channel:\n",
    "        img = img.mean(dim=0)\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    if one_channel:\n",
    "        plt.imshow(npimg, cmap=\"Greys\")\n",
    "    else:\n",
    "        plt.imshow(np.transpose(npimg, (1, 2, 0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 4 * 4, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 4 * 4)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "net = Net()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. TensorBoard 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "# 기본 `log_dir` 은 \"runs\"이며, 여기서는 더 구체적으로 지정하였습니다\n",
    "writer = SummaryWriter('runs/fashion_mnist_experiment_1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataiter = iter(trainloader)\n",
    "images, labels = next(dataiter)\n",
    "\n",
    "img_grid = torchvision.utils.make_grid(images)\n",
    "\n",
    "matplotlib_imshow(img_grid, one_channel=True)\n",
    "\n",
    "writer.add_image('four_fashion_mnist_images', img_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer.add_graph(net, images)\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "warning: Embedding dir exists, did you set global_step for add_embedding()?\n"
     ]
    }
   ],
   "source": [
    "def select_n_random(data, labels, n=100):\n",
    "    assert len(data) == len(labels)\n",
    "\n",
    "    perm = torch.randperm(len(data))\n",
    "    return data[perm][:n], labels[perm][:n]\n",
    "\n",
    "images, labels = select_n_random(trainset.data, trainset.targets)\n",
    "\n",
    "class_labels = [classes[lab] for lab in labels]\n",
    "\n",
    "features = images.view(-1, 28 * 28)\n",
    "writer.add_embedding(features,\n",
    "metadata=class_labels,\n",
    "label_img=images.unsqueeze(1))\n",
    "\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 텐서보드로 모델 학습 추적하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def images_to_probs(net, images):\n",
    "    output = net(images)\n",
    "    _, preds_tensor = torch.max(output, 1)\n",
    "    preds = np.squeeze(preds_tensor.numpy())\n",
    "    return preds, [F.softmax(el, dim=0)[i].item() for i, el in zip(preds, output)]\n",
    "\n",
    "def plot_classes_preds(net, images, labels):\n",
    "    preds, probs = images_to_probs(net, images)\n",
    "    fig = plt.figure(figsize=(12, 48))\n",
    "    for idx in np.arange(4):\n",
    "        ax = fig.add_subplot(1, 4, idx+1, xticks=[], yticks=[])\n",
    "        matplotlib_imshow(images[idx], one_channel=True)\n",
    "        ax.set_title(\"{0}, {1:.1f}%\\n(label: {2})\".format(\n",
    "            classes[preds[idx]],\n",
    "            probs[idx] * 100.0,\n",
    "            classes[labels[idx]]),\n",
    "                    color=(\"green\" if preds[idx]==labels[idx].item() else \"red\"))\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "running_loss = 0.0\n",
    "for epoch in range(1):\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "\n",
    "        inputs, labels = data\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "        if i % 1000 == 999:\n",
    "            writer.add_scalar(\"training loss\",\n",
    "                            running_loss/1000,\n",
    "                            epoch * len(trainloader) + i)\n",
    "            writer.add_figure(\"priction vs. actuals\",\n",
    "                            plot_classes_preds(net, inputs, labels),\n",
    "                            global_step=epoch * len(trainloader) + i)\n",
    "            running_loss = 0.0\n",
    "\n",
    "print(\"Finished Training\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.텐서보드로 학습된 모델 평가하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "weights should have the same shape as a.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[81], line 27\u001b[0m\n\u001b[1;32m     24\u001b[0m     writer\u001b[38;5;241m.\u001b[39mclose\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(classes)):\n\u001b[0;32m---> 27\u001b[0m     add_pr_curve_tensorboard(i, test_probs, test_preds)\n",
      "Cell \u001b[0;32mIn[81], line 19\u001b[0m, in \u001b[0;36madd_pr_curve_tensorboard\u001b[0;34m(class_index, test_probs, test_label, global_step)\u001b[0m\n\u001b[1;32m     16\u001b[0m tensorboard_truth \u001b[38;5;241m=\u001b[39m test_label \u001b[38;5;241m==\u001b[39m class_index\n\u001b[1;32m     17\u001b[0m tensorboard_probs \u001b[38;5;241m=\u001b[39m test_probs[:, class_index]\n\u001b[0;32m---> 19\u001b[0m writer\u001b[38;5;241m.\u001b[39madd_pr_curve(classes[class_index],\n\u001b[1;32m     20\u001b[0m                     tensorboard_truth,\n\u001b[1;32m     21\u001b[0m                     tensorboard_probs,\n\u001b[1;32m     22\u001b[0m                     global_step\u001b[38;5;241m=\u001b[39mglobal_step)\n\u001b[1;32m     24\u001b[0m writer\u001b[38;5;241m.\u001b[39mclose\n",
      "File \u001b[0;32m~/anaconda3/envs/torch/lib/python3.11/site-packages/torch/utils/tensorboard/writer.py:1002\u001b[0m, in \u001b[0;36mSummaryWriter.add_pr_curve\u001b[0;34m(self, tag, labels, predictions, global_step, num_thresholds, weights, walltime)\u001b[0m\n\u001b[1;32m    999\u001b[0m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_log_api_usage_once(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtensorboard.logging.add_pr_curve\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1000\u001b[0m labels, predictions \u001b[38;5;241m=\u001b[39m make_np(labels), make_np(predictions)\n\u001b[1;32m   1001\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_file_writer()\u001b[38;5;241m.\u001b[39madd_summary(\n\u001b[0;32m-> 1002\u001b[0m     pr_curve(tag, labels, predictions, num_thresholds, weights),\n\u001b[1;32m   1003\u001b[0m     global_step,\n\u001b[1;32m   1004\u001b[0m     walltime,\n\u001b[1;32m   1005\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/envs/torch/lib/python3.11/site-packages/torch/utils/tensorboard/summary.py:806\u001b[0m, in \u001b[0;36mpr_curve\u001b[0;34m(tag, labels, predictions, num_thresholds, weights)\u001b[0m\n\u001b[1;32m    803\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpr_curve\u001b[39m(tag, labels, predictions, num_thresholds\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m127\u001b[39m, weights\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    804\u001b[0m     \u001b[38;5;66;03m# weird, value > 127 breaks protobuf\u001b[39;00m\n\u001b[1;32m    805\u001b[0m     num_thresholds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmin\u001b[39m(num_thresholds, \u001b[38;5;241m127\u001b[39m)\n\u001b[0;32m--> 806\u001b[0m     data \u001b[38;5;241m=\u001b[39m compute_curve(\n\u001b[1;32m    807\u001b[0m         labels, predictions, num_thresholds\u001b[38;5;241m=\u001b[39mnum_thresholds, weights\u001b[38;5;241m=\u001b[39mweights\n\u001b[1;32m    808\u001b[0m     )\n\u001b[1;32m    809\u001b[0m     pr_curve_plugin_data \u001b[38;5;241m=\u001b[39m PrCurvePluginData(\n\u001b[1;32m    810\u001b[0m         version\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, num_thresholds\u001b[38;5;241m=\u001b[39mnum_thresholds\n\u001b[1;32m    811\u001b[0m     )\u001b[38;5;241m.\u001b[39mSerializeToString()\n\u001b[1;32m    812\u001b[0m     plugin_data \u001b[38;5;241m=\u001b[39m SummaryMetadata\u001b[38;5;241m.\u001b[39mPluginData(\n\u001b[1;32m    813\u001b[0m         plugin_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpr_curves\u001b[39m\u001b[38;5;124m\"\u001b[39m, content\u001b[38;5;241m=\u001b[39mpr_curve_plugin_data\n\u001b[1;32m    814\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/envs/torch/lib/python3.11/site-packages/torch/utils/tensorboard/summary.py:840\u001b[0m, in \u001b[0;36mcompute_curve\u001b[0;34m(labels, predictions, num_thresholds, weights)\u001b[0m\n\u001b[1;32m    838\u001b[0m float_labels \u001b[38;5;241m=\u001b[39m labels\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39mfloat64)\n\u001b[1;32m    839\u001b[0m histogram_range \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m0\u001b[39m, num_thresholds \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m--> 840\u001b[0m tp_buckets, _ \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mhistogram(\n\u001b[1;32m    841\u001b[0m     bucket_indices,\n\u001b[1;32m    842\u001b[0m     bins\u001b[38;5;241m=\u001b[39mnum_thresholds,\n\u001b[1;32m    843\u001b[0m     \u001b[38;5;28mrange\u001b[39m\u001b[38;5;241m=\u001b[39mhistogram_range,\n\u001b[1;32m    844\u001b[0m     weights\u001b[38;5;241m=\u001b[39mfloat_labels \u001b[38;5;241m*\u001b[39m weights,\n\u001b[1;32m    845\u001b[0m )\n\u001b[1;32m    846\u001b[0m fp_buckets, _ \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mhistogram(\n\u001b[1;32m    847\u001b[0m     bucket_indices,\n\u001b[1;32m    848\u001b[0m     bins\u001b[38;5;241m=\u001b[39mnum_thresholds,\n\u001b[1;32m    849\u001b[0m     \u001b[38;5;28mrange\u001b[39m\u001b[38;5;241m=\u001b[39mhistogram_range,\n\u001b[1;32m    850\u001b[0m     weights\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m1.0\u001b[39m \u001b[38;5;241m-\u001b[39m float_labels) \u001b[38;5;241m*\u001b[39m weights,\n\u001b[1;32m    851\u001b[0m )\n\u001b[1;32m    853\u001b[0m \u001b[38;5;66;03m# Obtain the reverse cumulative sum.\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/torch/lib/python3.11/site-packages/numpy/lib/histograms.py:778\u001b[0m, in \u001b[0;36mhistogram\u001b[0;34m(a, bins, range, density, weights)\u001b[0m\n\u001b[1;32m    678\u001b[0m \u001b[38;5;129m@array_function_dispatch\u001b[39m(_histogram_dispatcher)\n\u001b[1;32m    679\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mhistogram\u001b[39m(a, bins\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, \u001b[38;5;28mrange\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, density\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, weights\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    680\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    681\u001b[0m \u001b[38;5;124;03m    Compute the histogram of a dataset.\u001b[39;00m\n\u001b[1;32m    682\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    776\u001b[0m \n\u001b[1;32m    777\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 778\u001b[0m     a, weights \u001b[38;5;241m=\u001b[39m _ravel_and_check_weights(a, weights)\n\u001b[1;32m    780\u001b[0m     bin_edges, uniform_bins \u001b[38;5;241m=\u001b[39m _get_bin_edges(a, bins, \u001b[38;5;28mrange\u001b[39m, weights)\n\u001b[1;32m    782\u001b[0m     \u001b[38;5;66;03m# Histogram is an integer or a float array depending on the weights.\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/torch/lib/python3.11/site-packages/numpy/lib/histograms.py:297\u001b[0m, in \u001b[0;36m_ravel_and_check_weights\u001b[0;34m(a, weights)\u001b[0m\n\u001b[1;32m    295\u001b[0m     weights \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(weights)\n\u001b[1;32m    296\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m weights\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;241m!=\u001b[39m a\u001b[38;5;241m.\u001b[39mshape:\n\u001b[0;32m--> 297\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    298\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mweights should have the same shape as a.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    299\u001b[0m     weights \u001b[38;5;241m=\u001b[39m weights\u001b[38;5;241m.\u001b[39mravel()\n\u001b[1;32m    300\u001b[0m a \u001b[38;5;241m=\u001b[39m a\u001b[38;5;241m.\u001b[39mravel()\n",
      "\u001b[0;31mValueError\u001b[0m: weights should have the same shape as a."
     ]
    }
   ],
   "source": [
    "class_probs = []\n",
    "class_label = []\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        output = net(images)\n",
    "        class_probs_batch = [F.softmax(el, dim=0) for el in output]\n",
    "\n",
    "        class_probs.append(class_probs_batch)\n",
    "        class_label.append(labels)\n",
    "\n",
    "test_probs = torch.cat([torch.stack(batch) for batch in class_probs])\n",
    "test_label = torch.cat(class_label)\n",
    "\n",
    "def add_pr_curve_tensorboard(class_index, test_probs, test_label, global_step=0):\n",
    "    tensorboard_truth = test_label == class_index\n",
    "    tensorboard_probs = test_probs[:, class_index]\n",
    "\n",
    "    writer.add_pr_curve(classes[class_index],\n",
    "                        tensorboard_truth,\n",
    "                        tensorboard_probs,\n",
    "                        global_step=global_step)\n",
    "\n",
    "    writer.close\n",
    "\n",
    "for i in range(len(classes)):\n",
    "    add_pr_curve_tensorboard(i, test_probs, test_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
