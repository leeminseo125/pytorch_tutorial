{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 예제로 배우는 파이토치"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 텐서"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 준비운동: numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99 2396.0763544671104\n",
      "199 1770.8972180132923\n",
      "299 1319.1483079716904\n",
      "399 991.5956926215016\n",
      "499 753.1808115854881\n",
      "599 578.8958957329253\n",
      "699 450.87716704873947\n",
      "799 356.3428286926286\n",
      "899 286.12966592262643\n",
      "999 233.65392497705454\n",
      "1099 194.17299631855855\n",
      "1199 164.26043632053816\n",
      "1299 141.43235664990522\n",
      "1399 123.8812643011216\n",
      "1499 110.28622105111519\n",
      "1599 99.67724748244078\n",
      "1699 91.33831260659039\n",
      "1799 84.73779631971153\n",
      "1899 79.4785340845968\n",
      "1999 75.2618376348419\n",
      "Result: y = 1.603985272729849 + -1.828428970900139x + 0.03807204379784221x^2 + -0.1136313537541581X^3\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "\n",
    "x = np.linspace(-math.pi, math.pi, 2000)\n",
    "y = np.sin(x)\n",
    "\n",
    "a = np.random.randn()\n",
    "b = np.random.randn()\n",
    "c = np.random.randn()\n",
    "d = np.random.randn()\n",
    "\n",
    "learning_rate = 1e-6\n",
    "for t in range(2000):\n",
    "    y_pred = a + b + x + c * x ** 2 + d * x ** 3\n",
    "\n",
    "    loss = np.square(y_pred - y).sum()\n",
    "    if t % 100 == 99:\n",
    "        print(t, loss)\n",
    "\n",
    "    grad_y_pred = 2.0 * (y_pred - y)\n",
    "    grad_a = grad_y_pred.sum()\n",
    "    grad_b = (grad_y_pred * x).sum()\n",
    "    grad_c = (grad_y_pred * x ** 2).sum()\n",
    "    grad_d = (grad_y_pred * x ** 3).sum()\n",
    "\n",
    "    a -= learning_rate * grad_a\n",
    "    b -= learning_rate * grad_b\n",
    "    c -= learning_rate * grad_c\n",
    "    d -= learning_rate * grad_d\n",
    "\n",
    "print(f\"Result: y = {a} + {b}x + {c}x^2 + {d}X^3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 파이토치(Pytorch): 텐서(Tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99 1041.2509765625\n",
      "199 712.8997802734375\n",
      "299 489.52764892578125\n",
      "399 337.3980712890625\n",
      "499 233.67098999023438\n",
      "599 162.8655242919922\n",
      "699 114.47737121582031\n",
      "799 81.37104034423828\n",
      "899 58.694244384765625\n",
      "999 43.143497467041016\n",
      "1099 32.46736145019531\n",
      "1199 25.12946891784668\n",
      "1299 20.080347061157227\n",
      "1399 16.602294921875\n",
      "1499 14.203780174255371\n",
      "1599 12.547990798950195\n",
      "1699 11.403715133666992\n",
      "1799 10.612112045288086\n",
      "1899 10.063936233520508\n",
      "1999 9.68395709991455\n",
      "Result: y = -0.02690296061336994 + 0.8422964215278625 x + 0.004641206935048103 x^2 + -0.09127578884363174 x^3\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import math\n",
    "\n",
    "dtype = torch.float\n",
    "device = torch.device(\"cpu\")\n",
    "\n",
    "x = torch.linspace(-math.pi, math.pi, 2000, device=device, dtype=dtype)\n",
    "y = torch.sin(x)\n",
    "\n",
    "a = torch.randn((), device=device, dtype=dtype)\n",
    "b = torch.randn((), device=device, dtype=dtype)\n",
    "c = torch.randn((), device=device, dtype=dtype)\n",
    "d = torch.randn((), device=device, dtype=dtype)\n",
    "\n",
    "learning_rate = 1e-6\n",
    "for t in range(2000):\n",
    "    y_pred = a + b*x + c*x**2 + d*x**3\n",
    "\n",
    "    loss = (y_pred - y).pow(2).sum().item()\n",
    "    if t % 100 == 99:\n",
    "        print(t, loss)\n",
    "\n",
    "    grad_y_pred = 2.0 * (y_pred - y)\n",
    "    grad_a = grad_y_pred.sum()\n",
    "    grad_b = (grad_y_pred * x).sum()\n",
    "    grad_c = (grad_y_pred * x ** 2).sum()\n",
    "    grad_d = (grad_y_pred * x ** 3).sum()\n",
    "\n",
    "    a -= learning_rate * grad_a\n",
    "    b -= learning_rate * grad_b\n",
    "    c -= learning_rate * grad_c\n",
    "    d -= learning_rate * grad_d\n",
    "\n",
    "print(f'Result: y = {a.item()} + {b.item()} x + {c.item()} x^2 + {d.item()} x^3')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Autograd\n",
    "### PyTorch: 텐서와 autograd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99 1137.4031982421875\n",
      "199 785.8331298828125\n",
      "299 544.3726806640625\n",
      "399 378.34771728515625\n",
      "499 264.06298828125\n",
      "599 185.30755615234375\n",
      "699 130.97682189941406\n",
      "799 93.45578002929688\n",
      "899 67.51637268066406\n",
      "999 49.565223693847656\n",
      "1099 37.129913330078125\n",
      "1199 28.507122039794922\n",
      "1299 22.522258758544922\n",
      "1399 18.364484786987305\n",
      "1499 15.473392486572266\n",
      "1599 13.461374282836914\n",
      "1699 12.059953689575195\n",
      "1799 11.083028793334961\n",
      "1899 10.401504516601562\n",
      "1999 9.925701141357422\n",
      "Result: y = 0.03225264698266983 + <built-in method item of Tensor object at 0x7fa843aec590>x + <built-in method item of Tensor object at 0x7fa7920e6ab0>x^2 + <built-in method item of Tensor object at 0x7fa7920e6c90>x^3\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import math\n",
    "\n",
    "dtype = torch.float\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "torch.set_default_device(device)\n",
    "\n",
    "x = torch.linspace(-math.pi, math.pi, 2000, dtype=dtype)\n",
    "y = torch.sin(x)\n",
    "\n",
    "a = torch.randn((), dtype=dtype, requires_grad=True)\n",
    "b = torch.randn((), dtype=dtype, requires_grad=True)\n",
    "c = torch.randn((), dtype=dtype, requires_grad=True)\n",
    "d = torch.randn((), dtype=dtype, requires_grad=True)\n",
    "\n",
    "learning_rate = 1e-6\n",
    "for t in range(2000):\n",
    "    y_pred = a + b*x + c*x**2 + d*x**3\n",
    "\n",
    "    loss = (y_pred -y).pow(2).sum()\n",
    "    if t % 100 == 99:\n",
    "        print(t, loss.item())\n",
    "    \n",
    "    loss.backward()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        a -= learning_rate * a.grad\n",
    "        b -= learning_rate * b.grad\n",
    "        c -= learning_rate * c.grad\n",
    "        d -= learning_rate * d.grad\n",
    "\n",
    "        a.grad = None\n",
    "        b.grad = None\n",
    "        c.grad = None\n",
    "        d.grad = None\n",
    "\n",
    "print(f\"Result: y = {a.item()} + {b.item}x + {c.item}x^2 + {d.item}x^3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pytorch: 새 autograd Function 정의하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99 209.95834350585938\n",
      "199 144.66018676757812\n",
      "299 100.70249938964844\n",
      "399 71.03519439697266\n",
      "499 50.978511810302734\n",
      "599 37.403133392333984\n",
      "699 28.206867218017578\n",
      "799 21.97318458557129\n",
      "899 17.7457275390625\n",
      "999 14.877889633178711\n",
      "1099 12.93176555633545\n",
      "1199 11.610918045043945\n",
      "1299 10.71425724029541\n",
      "1399 10.10548210144043\n",
      "1499 9.692105293273926\n",
      "1599 9.411375999450684\n",
      "1699 9.220745086669922\n",
      "1799 9.091285705566406\n",
      "1899 9.003361701965332\n",
      "1999 8.943641662597656\n",
      "Result: y = -6.71270206087371e-10 + -2.208526849746704 * P3(-3.392665037793563e-10 + 0.2554861009120941 x)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import math\n",
    "\n",
    "class LegendrePolynomial3(torch.autograd.Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, input):\n",
    "        ctx.save_for_backward(input)\n",
    "        return 0.5 * (5 * input ** 3 - 3 * input)\n",
    "    \n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        input, = ctx.saved_tensors\n",
    "        return grad_output * 1.5 * (5 * input ** 2 - 1)\n",
    "    \n",
    "dtype = torch.float\n",
    "device = torch.device(\"cpu\")\n",
    "\n",
    "# 입력값과 출력값을 갖는 텐서들을 생성\n",
    "x = torch.linspace(-math.pi, math.pi, 2000, device = device, dtype = dtype)\n",
    "y = torch.sin(x)\n",
    "\n",
    "# 가중치를 갖는 임의의 텐서를 생성, 3차 다항식이므로 4개의 가중치가 필요\n",
    "\n",
    "a = torch.full((), 0.0, device=device, dtype=dtype, requires_grad=True)\n",
    "b = torch.full((), -1.0, device=device, dtype=dtype, requires_grad=True)\n",
    "c = torch.full((), 0.0, device=device, dtype=dtype, requires_grad=True)\n",
    "d = torch.full((), 0.3, device=device, dtype=dtype, requires_grad=True)\n",
    "\n",
    "learning_rate = 5e-6\n",
    "for t in range(2000):\n",
    "    P3 = LegendrePolynomial3.apply\n",
    "\n",
    "    y_pred = a + b * P3(c + d * x)\n",
    "    \n",
    "    loss = (y_pred - y).pow(2).sum()\n",
    "    if t % 100 == 99:\n",
    "        print(t, loss.item())\n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        a -= learning_rate * a.grad\n",
    "        b -= learning_rate * b.grad\n",
    "        c -= learning_rate * c.grad\n",
    "        d -= learning_rate * d.grad\n",
    "\n",
    "        a.grad = None\n",
    "        b.grad = None\n",
    "        c.grad = None\n",
    "        d.grad = None\n",
    "\n",
    "print(f'Result: y = {a.item()} + {b.item()} * P3({c.item()} + {d.item()} x)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## nn모듈"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99 1389.775390625\n",
      "199 922.7545166015625\n",
      "299 613.709716796875\n",
      "399 409.19244384765625\n",
      "499 273.8414306640625\n",
      "599 184.2598114013672\n",
      "699 124.96697235107422\n",
      "799 85.7191162109375\n",
      "899 59.737815856933594\n",
      "999 42.53746032714844\n",
      "1099 31.149349212646484\n",
      "1199 23.60885238647461\n",
      "1299 18.615478515625\n",
      "1399 15.308577537536621\n",
      "1499 13.118315696716309\n",
      "1599 11.66740608215332\n",
      "1699 10.70625114440918\n",
      "1799 10.069391250610352\n",
      "1899 9.647388458251953\n",
      "1999 9.367691040039062\n",
      "Result: y = 0.005132834892719984 + 0.8344249725341797 x + -0.0008854999905452132 x^2 + -0.09015615284442902 x^3\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import math\n",
    "\n",
    "x = torch.linspace(-math.pi, math.pi, 2000)\n",
    "y = torch.sin(x)\n",
    "\n",
    "p = torch.tensor([1, 2, 3])\n",
    "xx = x.unsqueeze(-1).pow(p)\n",
    "\n",
    "model = torch.nn.Sequential(\n",
    "    torch.nn.Linear(3, 1),\n",
    "    torch.nn.Flatten(0, 1)\n",
    ")\n",
    "\n",
    "loss_fn = torch.nn.MSELoss(reduction='sum')\n",
    "learning_rate = 1e-6\n",
    "for t in range(2000):\n",
    "    y_pred = model(xx)\n",
    "    loss = loss_fn(y_pred, y)\n",
    "    if t % 100 == 99:\n",
    "        print(t, loss.item())\n",
    "\n",
    "    model.zero_grad()\n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for param in model.parameters():\n",
    "            param -= learning_rate * param.grad\n",
    "\n",
    "linear_layer = model[0]\n",
    "\n",
    "print(f'Result: y = {linear_layer.bias.item()} + {linear_layer.weight[:, 0].item()} x + {linear_layer.weight[:, 1].item()} x^2 + {linear_layer.weight[:, 2].item()} x^3')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PyTorch: optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99 13218.296875\n",
      "199 4496.5830078125\n",
      "299 1419.328369140625\n",
      "399 641.0751953125\n",
      "499 498.46990966796875\n",
      "599 425.03192138671875\n",
      "699 350.4445495605469\n",
      "799 274.3376159667969\n",
      "899 201.9947509765625\n",
      "999 138.92855834960938\n",
      "1099 88.4695816040039\n",
      "1199 51.748779296875\n",
      "1299 28.026073455810547\n",
      "1399 15.205949783325195\n",
      "1499 10.11483383178711\n",
      "1599 9.077219009399414\n",
      "1699 8.843135833740234\n",
      "1799 8.908886909484863\n",
      "1899 8.979445457458496\n",
      "1999 8.905778884887695\n",
      "Result: y = -3.39617116651425e-08 + 0.8562856912612915 x + -3.366927003867204e-08 x^2 + -0.09381669014692307 x^3\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import math\n",
    "\n",
    "x = torch.linspace(-math.pi, math.pi, 2000)\n",
    "y = torch.sin(x)\n",
    "\n",
    "p = torch.tensor([1, 2, 3])\n",
    "xx = x.unsqueeze(-1).pow(p)\n",
    "\n",
    "model = torch.nn.Sequential(\n",
    "    torch.nn.Linear(3, 1),\n",
    "    torch.nn.Flatten(0, 1)\n",
    ")\n",
    "model_fn = torch.nn.MSELoss(reduction = 'sum')\n",
    "\n",
    "learning_rate = 1e-3\n",
    "optimizer = torch.optim.RMSprop(model.parameters(), lr = learning_rate)\n",
    "for t in range(2000):\n",
    "    # 순전파 단계: 모델에 x를 전달하여 예측값 y를 계산합니다.\n",
    "    y_pred = model(xx)\n",
    "\n",
    "    loss = loss_fn(y_pred, y)\n",
    "    if t % 100 == 99:\n",
    "        print(t, loss.item())\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    #역전파 단계\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "linear_layer = model[0]\n",
    "print(f'Result: y = {linear_layer.bias.item()} + {linear_layer.weight[:, 0].item()} x + {linear_layer.weight[:, 1].item()} x^2 + {linear_layer.weight[:, 2].item()} x^3')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 사용자 정의 nn 모듈"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99 1103.344970703125\n",
      "199 735.394287109375\n",
      "299 491.2627868652344\n",
      "399 329.2471923828125\n",
      "499 221.70132446289062\n",
      "599 150.29440307617188\n",
      "699 102.86955261230469\n",
      "799 71.36370849609375\n",
      "899 50.42681884765625\n",
      "999 36.5090446472168\n",
      "1099 27.253990173339844\n",
      "1199 21.097396850585938\n",
      "1299 17.000333786010742\n",
      "1399 14.272804260253906\n",
      "1499 12.456226348876953\n",
      "1599 11.245759010314941\n",
      "1699 10.438852310180664\n",
      "1799 9.900655746459961\n",
      "1899 9.54153060913086\n",
      "1999 9.30174446105957\n",
      "Result: y = 0.009769970551133156 + 0.8373141288757324 x + -0.0016854822169989347 x^2 + -0.09056710451841354 x^3\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import math\n",
    "\n",
    "class Polynomial3(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.a = torch.nn.Parameter(torch.randn(()))\n",
    "        self.b = torch.nn.Parameter(torch.randn(()))\n",
    "        self.c = torch.nn.Parameter(torch.randn(()))\n",
    "        self.d = torch.nn.Parameter(torch.randn(()))\n",
    "\n",
    "    def forward(self, x):\n",
    "         return self.a + self.b * x + self.c * x ** 2 + self.d * x ** 3\n",
    "    \n",
    "    def string(self):\n",
    "        return f'y = {self.a.item()} + {self.b.item()} x + {self.c.item()} x^2 + {self.d.item()} x^3'\n",
    "\n",
    "x = torch.linspace(-math.pi, math.pi, 2000)\n",
    "y = torch.sin(x)\n",
    "\n",
    "model = Polynomial3()\n",
    "\n",
    "criterion = torch.nn.MSELoss(reduction='sum')\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-6)\n",
    "for t in range(2000):\n",
    "    y_pred = model(x)\n",
    "    \n",
    "    loss = criterion(y_pred, y)\n",
    "    if t % 100 == 99:\n",
    "        print(t, loss.item())\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "print(f'Result: {model.string()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PyTorch: 제어흐름 + 가중치 공유"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1999 1054.506591796875\n",
      "3999 450.39984130859375\n",
      "5999 214.65936279296875\n",
      "7999 100.25425720214844\n",
      "9999 49.076385498046875\n",
      "11999 26.642013549804688\n",
      "13999 16.75096893310547\n",
      "15999 12.294881820678711\n",
      "17999 10.304195404052734\n",
      "19999 9.523414611816406\n",
      "21999 8.960441589355469\n",
      "23999 8.773473739624023\n",
      "25999 8.89212417602539\n",
      "27999 8.629688262939453\n",
      "29999 8.853524208068848\n",
      "Result: y = 0.0023367558605968952 + 0.8545345067977905x + -0.0010018933098763227x^2 + -0.09332714974880219x^3 + 0.0001054343010764569x^4 + 0.0001054343010764569x^5 ?\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import torch\n",
    "import math\n",
    "\n",
    "class DynamicNet(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.a = torch.nn.Parameter(torch.randn(()))\n",
    "        self.b = torch.nn.Parameter(torch.randn(()))\n",
    "        self.c = torch.nn.Parameter(torch.randn(()))\n",
    "        self.d = torch.nn.Parameter(torch.randn(()))\n",
    "        self.e = torch.nn.Parameter(torch.randn(()))\n",
    "\n",
    "    def forward(self, x):\n",
    "        y = self.a + self.b * x + self.c * x ** 2 + self.d * x **3\n",
    "        for exp in range(4, random.randint(4, 6)):\n",
    "            y = y + self.e * x ** exp\n",
    "        return y\n",
    "    \n",
    "    def string(self):\n",
    "        return f'y = {self.a.item()} + {self.b.item()}x + {self.c.item()}x^2 + {self.d.item()}x^3 + {self.e.item()}x^4 + {self.e.item()}x^5 ?'\n",
    "    \n",
    "x = torch.linspace(-math.pi, math.pi, 2000)\n",
    "y = torch.sin(x)\n",
    "\n",
    "model = DynamicNet()\n",
    "\n",
    "criterion = torch.nn.MSELoss(reduction='sum')\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-8, momentum=0.9)\n",
    "for t in range(30000):\n",
    "    y_pred = model(x)\n",
    "\n",
    "    loss = criterion(y_pred, y)\n",
    "    if t % 2000 == 1999:\n",
    "        print(t, loss.item())\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "print(f'Result: {model.string()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
